{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMb1Tr1odWfMN7ugMvu5GsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vanbk/Tensorflow/blob/master/rnn_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G52wR2fPw2T",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtNqu5Yy_dda",
        "colab_type": "code",
        "outputId": "645177f0-4d64-44dc-e285-e384215d2eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-02f6518a87fd>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrZfFa5rQnzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez-eX1HV_lsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "To classify images using a recurrent neural network, \n",
        "we consider every image row as a sequence of pixels. \n",
        "Because MNIST image shape is 28*28px, we will then handle \n",
        "28 sequences of 28 timesteps for every sample.\n",
        "'''\n",
        "\n",
        "# Training Parameter\n",
        "learning_rate = 0.001\n",
        "training_steps = 10000\n",
        "batch_size = 128\n",
        "display_step = 200\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 28 #MNIST image size = (28 * 28)\n",
        "timesteps = 28 \n",
        "#If the input 𝑥 is of size 𝑛×1, and we have 𝑑 hidden states, \n",
        "#then the size of the total weight matrix is 4𝑑×(𝑛+𝑑)\n",
        "#(the total weight matrix includes parameters for all 4 \n",
        "# operations and the sub matrices W and U)\n",
        "num_hidden = 128 # hidden states\n",
        "num_classes = 10 # MNIST total classes (0 - 9)\n",
        "\n",
        "# tf Graph\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None,timesteps, num_input])\n",
        "Y = tf.placeholder(tf.float32, [None, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opiPR9VfD6zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define weights for the last layer, which is used for classification\n",
        "# RNN output node weights and biases\n",
        "\n",
        "weights = {\n",
        "    #Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
        "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfGePm6nKSr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RNN(x, weights, biases):\n",
        "  # input shape x: (batch_size, timesteps, n_input)\n",
        "  # Required shape: 'timesteps' tensor list of shape (batch_size, n_input)\n",
        "  x = tf.unstack(x, timesteps, 1)\n",
        "\n",
        "  # Define a lstm cell\n",
        "  lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
        "\n",
        "  # Get lstm cell ouput\n",
        "  outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "  # the last layer is a dense layer\n",
        "  return tf.matmul(outputs[-1], weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiTSnoQZPhTk",
        "colab_type": "code",
        "outputId": "263adaca-f7ee-432d-c0bd-41d99102dcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# softmax classification\n",
        "logits = RNN(X, weights, biases)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# reduce_mean <=> average\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "# 1 in argmax means horizontal\n",
        "correct_pre = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(Y, 1))\n",
        "# tf cast convert correct_pre to float before dividing -> get a float accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pre, tf.float32))\n",
        "\n",
        "# Initialize the variables \n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-42acebb9d451>:7: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-5-42acebb9d451>:10: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-6-4a6e3a446985>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raQCpi61HnMo",
        "colab_type": "code",
        "outputId": "a1797d00-9316-4fa2-d5b8-fe76824bd833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "sess.run(init)\n",
        "\n",
        "for step in range (1, training_steps + 1):\n",
        "  batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "  #reshape data to 28 * 28\n",
        "  batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "  # Run iptimization op\n",
        "  sess.run(optimizer, feed_dict={X:batch_x, Y: batch_y})\n",
        "\n",
        "  if step % display_step == 0 or step == 1:\n",
        "    loss, acc = sess.run([loss_op, accuracy ], feed_dict={X:batch_x, Y: batch_y})\n",
        "    print (\"Step: {}  batch_loss: {}  train_acc:{}\".format(step, loss, acc))\n",
        "print (\"Training finish !\")\n",
        "\n",
        "# Calculate accuracy for 128 mnist test images\n",
        "test_len = 128\n",
        "test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
        "test_label = mnist.test.labels[:test_len]\n",
        "test_acc =  sess.run(accuracy, feed_dict={X: test_data, Y: test_label})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 1  batch_loss: 3.1400885581970215  train_acc:0.046875\n",
            "Step: 200  batch_loss: 2.1707303524017334  train_acc:0.2109375\n",
            "Step: 400  batch_loss: 2.0485823154449463  train_acc:0.2578125\n",
            "Step: 600  batch_loss: 1.7530176639556885  train_acc:0.5\n",
            "Step: 800  batch_loss: 1.675374150276184  train_acc:0.515625\n",
            "Step: 1000  batch_loss: 1.6245977878570557  train_acc:0.46875\n",
            "Step: 1200  batch_loss: 1.5314277410507202  train_acc:0.5\n",
            "Step: 1400  batch_loss: 1.28299081325531  train_acc:0.6171875\n",
            "Step: 1600  batch_loss: 1.436321496963501  train_acc:0.515625\n",
            "Step: 1800  batch_loss: 1.3278319835662842  train_acc:0.5546875\n",
            "Step: 2000  batch_loss: 1.3676435947418213  train_acc:0.6015625\n",
            "Step: 2200  batch_loss: 1.222402811050415  train_acc:0.59375\n",
            "Step: 2400  batch_loss: 1.2574543952941895  train_acc:0.5390625\n",
            "Step: 2600  batch_loss: 1.195747971534729  train_acc:0.6484375\n",
            "Step: 2800  batch_loss: 1.1344588994979858  train_acc:0.640625\n",
            "Step: 3000  batch_loss: 1.0597310066223145  train_acc:0.65625\n",
            "Step: 3200  batch_loss: 1.0120700597763062  train_acc:0.703125\n",
            "Step: 3400  batch_loss: 1.139775037765503  train_acc:0.6328125\n",
            "Step: 3600  batch_loss: 1.0251277685165405  train_acc:0.6796875\n",
            "Step: 3800  batch_loss: 0.9694774150848389  train_acc:0.7109375\n",
            "Step: 4000  batch_loss: 1.02882981300354  train_acc:0.7421875\n",
            "Step: 4200  batch_loss: 0.8717801570892334  train_acc:0.6875\n",
            "Step: 4400  batch_loss: 0.7902815937995911  train_acc:0.75\n",
            "Step: 4600  batch_loss: 0.7972853183746338  train_acc:0.75\n",
            "Step: 4800  batch_loss: 0.832915723323822  train_acc:0.7421875\n",
            "Step: 5000  batch_loss: 0.9421049356460571  train_acc:0.7265625\n",
            "Step: 5200  batch_loss: 0.8804820775985718  train_acc:0.671875\n",
            "Step: 5400  batch_loss: 0.569582998752594  train_acc:0.84375\n",
            "Step: 5600  batch_loss: 0.8301759958267212  train_acc:0.765625\n",
            "Step: 5800  batch_loss: 0.6893148422241211  train_acc:0.75\n",
            "Step: 6000  batch_loss: 0.630347728729248  train_acc:0.8125\n",
            "Step: 6200  batch_loss: 0.5777972936630249  train_acc:0.8125\n",
            "Step: 6400  batch_loss: 0.6644835472106934  train_acc:0.7734375\n",
            "Step: 6600  batch_loss: 0.750077486038208  train_acc:0.7890625\n",
            "Step: 6800  batch_loss: 0.691969633102417  train_acc:0.78125\n",
            "Step: 7000  batch_loss: 0.6558065414428711  train_acc:0.7578125\n",
            "Step: 7200  batch_loss: 0.638007640838623  train_acc:0.78125\n",
            "Step: 7400  batch_loss: 0.5681026577949524  train_acc:0.84375\n",
            "Step: 7600  batch_loss: 0.5466331243515015  train_acc:0.8359375\n",
            "Step: 7800  batch_loss: 0.6054742932319641  train_acc:0.8515625\n",
            "Step: 8000  batch_loss: 0.4917302429676056  train_acc:0.84375\n",
            "Step: 8200  batch_loss: 0.5705106854438782  train_acc:0.859375\n",
            "Step: 8400  batch_loss: 0.5126861929893494  train_acc:0.8515625\n",
            "Step: 8600  batch_loss: 0.5153000950813293  train_acc:0.8515625\n",
            "Step: 8800  batch_loss: 0.4505407214164734  train_acc:0.890625\n",
            "Step: 9000  batch_loss: 0.5709853172302246  train_acc:0.8125\n",
            "Step: 9200  batch_loss: 0.5936141014099121  train_acc:0.8515625\n",
            "Step: 9400  batch_loss: 0.5667184591293335  train_acc:0.8203125\n",
            "Step: 9600  batch_loss: 0.5114285945892334  train_acc:0.8046875\n",
            "Step: 9800  batch_loss: 0.448977530002594  train_acc:0.875\n",
            "Step: 10000  batch_loss: 0.49558424949645996  train_acc:0.84375\n",
            "Training finish !\n",
            "Testing accuracy: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63osBVsYr69",
        "colab_type": "code",
        "outputId": "d0428cb7-fd3d-4c5a-a0c6-e132ce3a1bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"Testing accuracy: \", test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy:  0.8828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omICqf6DXK6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}